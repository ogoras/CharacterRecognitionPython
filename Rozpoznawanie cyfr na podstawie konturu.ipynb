{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Przetwarzanie konturu na obraz rastrowy**\n",
    "\n",
    "Wczytywanie przykładowych plików"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parametry\n",
    "\n",
    "imside = 28\n",
    "padding = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-2f57f1e9498b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mcoords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m#transformacje związane z obróceniem tablicy w środowisku (powinno być trochę bardziej elegancko :?)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mvectors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmaximum_xs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[0mmaximum_xs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: ''"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "vectors = []\n",
    "maximum_xs = []\n",
    "maximum_ys = []\n",
    "minimum_xs = []\n",
    "minimum_ys = []\n",
    "i = 0\n",
    "\n",
    "directory = \"data/Contours/7\"\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    \n",
    "    vectors.append([])\n",
    "    f = open(directory + \"/\" + filename, \"r\")\n",
    "    maximum_xs.append(-math.inf)\n",
    "    maximum_ys.append(-math.inf)\n",
    "    minimum_xs.append(math.inf)\n",
    "    minimum_ys.append(math.inf)\n",
    "    \n",
    "    for line in f.readlines():\n",
    "        line = line[:-1]\n",
    "        coords = line.split(' ')\n",
    "#transformacje związane z obróceniem tablicy w środowisku (powinno być trochę bardziej elegancko :?)\n",
    "        vectors[i].append([float(coords[0]), -float(coords[1])])\n",
    "        if (maximum_xs[i] < float(coords[0])):\n",
    "            maximum_xs[i] = float(coords[0])\n",
    "        if (maximum_ys[i] < -float(coords[1])):\n",
    "            maximum_ys[i] = -float(coords[1])\n",
    "        if (minimum_xs[i] > float(coords[0])):\n",
    "            minimum_xs[i] = float(coords[0])\n",
    "        if (minimum_ys[i] > -float(coords[1])):\n",
    "            minimum_ys[i] = -float(coords[1])\n",
    "    i = i + 1\n",
    "\n",
    "num_of_pics = i\n",
    "print(vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_of_pics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-2bd77161af35>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnum_of_pics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'num_of_pics' is not defined"
     ]
    }
   ],
   "source": [
    "num_of_pics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Następnie normalizacja:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-eb4c9691ca75>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnorms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvectors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mrange_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaximum_xs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mminimum_xs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mrange_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaximum_ys\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mminimum_ys\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vectors' is not defined"
     ]
    }
   ],
   "source": [
    "imrange = imside - 2*padding\n",
    "i = 0\n",
    "norms = []\n",
    "\n",
    "for v in vectors:\n",
    "    range_x = maximum_xs[i] - minimum_xs[i]\n",
    "    range_y = maximum_ys[i] - minimum_ys[i]\n",
    "\n",
    "    maxrange = max(range_x , range_y)\n",
    "    if maxrange == 0:\n",
    "        norms.append([[imside/2, imside/2]])\n",
    "        i += 1\n",
    "        continue\n",
    "    ratio =  min(range_x, range_y) / maxrange\n",
    "    \n",
    "    if (range_x > range_y):\n",
    "        norms.append([[(vector[0]-minimum_xs[i])*imrange/maxrange + padding,\n",
    "                        (vector[1]-minimum_ys[i])*imrange/maxrange + padding + imrange*(1-ratio)/2] for vector in v])\n",
    "    else:\n",
    "        norms.append([[(vector[0]-minimum_xs[i])*imrange/maxrange + padding + imrange*(1-ratio)/2,\n",
    "                        (vector[1]-minimum_ys[i])*imrange/maxrange + padding] for vector in v])\n",
    "        \n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_of_pics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-17324fe1b83a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnum_of_pics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'num_of_pics' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "\n",
    "fig = plt.figure(figsize=(30, 8*num_of_pics))\n",
    "i = 1\n",
    "\n",
    "for norm in norms:\n",
    "    img = 255 * np.ones([imside,imside], dtype=np.uint8)\n",
    "    for point in norm:\n",
    "        img[int(point[0])][int(point[1])] = 0\n",
    "    plot = fig.add_subplot(num_of_pics,5,i)\n",
    "    plot.imshow(img,cmap='gray')\n",
    "    i = i + 1\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obliczam współczynniki dla parametrycznych krzywych Béziera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the a & b points\n",
    "def get_bezier_coef(points):\n",
    "    # since the formulas work given that we have n+1 points\n",
    "    # then n must be this:\n",
    "    n = len(points) - 1\n",
    "\n",
    "    # build coefficents matrix\n",
    "    C = 4 * np.identity(n)\n",
    "    np.fill_diagonal(C[1:], 1)\n",
    "    np.fill_diagonal(C[:, 1:], 1)\n",
    "    C[0, 0] = 2\n",
    "    C[n - 1, n - 1] = 7\n",
    "    C[n - 1, n - 2] = 2\n",
    "\n",
    "    # build points vector\n",
    "    P = [2 * (2 * points[i] + points[i + 1]) for i in range(n)]\n",
    "    P[0] = points[0] + 2 * points[1]\n",
    "    P[n - 1] = 8 * points[n - 1] + points[n]\n",
    "\n",
    "    # solve system, find a & b\n",
    "    A = np.linalg.solve(C, P)\n",
    "    B = [0] * n\n",
    "    for i in range(n - 1):\n",
    "        B[i] = 2 * points[i + 1] - A[i + 1]\n",
    "    B[n - 1] = (A[n - 1] + points[n]) / 2\n",
    "\n",
    "    return A, B\n",
    "\n",
    "# returns the general Bezier cubic formula given 4 control points\n",
    "def get_cubic(a, b, c, d):\n",
    "    return lambda t: np.power(1 - t, 3) * a + 3 * np.power(1 - t, 2) * t * b + 3 * (1 - t) * np.power(t, 2) * c + np.power(t, 3) * d\n",
    "\n",
    "# return one cubic curve for each consecutive points\n",
    "def get_bezier_cubic(points):\n",
    "    A, B = get_bezier_coef(points)\n",
    "    return [\n",
    "        get_cubic(points[i], A[i], B[i], points[i + 1])\n",
    "        for i in range(len(points) - 1)\n",
    "    ]\n",
    "\n",
    "# evalute each cubic curve on the range [0, 1] sliced in n points\n",
    "def evaluate_bezier(points, n):\n",
    "    curves = get_bezier_cubic(points)\n",
    "    return np.array([fun(t) for fun in curves for t in np.linspace(0, 1, n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-016ff6a0d085>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpoints\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnorms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_bezier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# extract x & y coordinates of points\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpoints\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpoints\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "points = np.array(norms[0])\n",
    "path = evaluate_bezier(points, 50)\n",
    "\n",
    "# extract x & y coordinates of points\n",
    "x, y = points[:,0], points[:,1]\n",
    "px, py = path[:,0], path[:,1]\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize=(11, 11))\n",
    "plt.plot(px, py, 'b-')\n",
    "plt.plot(x, y, 'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import io\n",
    "\n",
    "brush_size = 2\n",
    "factor = -(2.0/brush_size)**2\n",
    "\n",
    "imgs = []\n",
    "\n",
    "fig = plt.figure(figsize=(30, 8*num_of_pics))\n",
    "i = 1\n",
    "\n",
    "def draw_pixel(img, x, y, val):\n",
    "    if (x < 0 or x >= imside or y <0 or y >= imside):\n",
    "        return\n",
    "    if (255 - img[x][y] > val):\n",
    "        img[x][y] += val\n",
    "    else:\n",
    "        img[x][y] = 255\n",
    "\n",
    "def draw_dot(img, x, y):\n",
    "    for ox in range(-brush_size,brush_size+1):\n",
    "        for oy in range(-brush_size,brush_size+1):\n",
    "            draw_pixel(img, x+ox, y+oy, 20*math.exp( factor * (ox**2 + oy**2)))\n",
    "        \n",
    "for norm in norms:\n",
    "    img = 255 * np.zeros([imside,imside], dtype=np.uint8)\n",
    "    \n",
    "    if (len(norm) == 1):\n",
    "        draw_dot(img, int(norm[0][0]), int(norm[0][1]))\n",
    "    else:    \n",
    "        path = evaluate_bezier(np.array(norm), 50)\n",
    "        px, py = path[:,0], path[:,1]\n",
    "        n = len(px)\n",
    "        for index in range(n):\n",
    "            draw_dot(img, int(px[index]), int(py[index]))\n",
    "            \n",
    "    plot = fig.add_subplot(num_of_pics,5,i)\n",
    "    plot.imshow(img,cmap='Greys')\n",
    "    imgs.append(img)\n",
    "    i += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Klasyfikacja obrazów**\n",
    "\n",
    "Pobieram zbiór danych MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x233c1b794c0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_index = 429 # You may select anything up to 60,000\n",
    "print(y_train[image_index]) # The label is 8\n",
    "plt.imshow(x_train[image_index], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "Number of images in x_train 60000\n",
      "Number of images in x_test 10000\n"
     ]
    }
   ],
   "source": [
    "# Reshaping the array to 4-dims so that it can work with the Keras API\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)\n",
    "# Making sure that the values are float so that we can get decimal points after division\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "# Normalizing the RGB codes by dividing it to the max RGB value.\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('Number of images in x_train', x_train.shape[0])\n",
    "print('Number of images in x_test', x_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required Keras modules containing model and layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "# Creating a Sequential Model and adding the layers\n",
    "model = Sequential()\n",
    "model.add(Conv2D(28, kernel_size=(3,3), input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten()) # Flattening the 2D arrays for fully connected layers\n",
    "model.add(Dense(128, activation=tf.nn.relu))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10,activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.convolutional.Conv2D at 0x2bb08be95e0>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x2bb7b954100>,\n",
       " <tensorflow.python.keras.layers.core.Flatten at 0x2bb7decda60>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2bb084a3880>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x2bb7f618190>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2bb084b9ca0>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.3498 - accuracy: 0.8972\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0854 - accuracy: 0.9751\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0560 - accuracy: 0.9827\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0425 - accuracy: 0.9864\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0320 - accuracy: 0.9902\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0265 - accuracy: 0.9910\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0251 - accuracy: 0.9913\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0202 - accuracy: 0.9930\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0176 - accuracy: 0.9937\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0160 - accuracy: 0.9948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x229c0da33a0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(x=x_train,y=y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0633 - accuracy: 0.9855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06334307044744492, 0.9854999780654907]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "9\n",
      "2\n",
      "3\n",
      "4\n",
      "3\n",
      "6\n",
      "3\n",
      "8\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for img in imgs:\n",
    "    pred = model.predict(img.reshape(1, 28, 28, 1))\n",
    "    print(pred.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 683.5530 - accuracy: 0.8586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[683.552978515625, 0.8585858345031738]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(np.array(imgs).reshape(np.array(imgs).shape[0],imside,imside,1), np.zeros(num_of_pics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":((("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2, -1,  0,  1])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(range(-2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.38905609893065"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.exp(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
